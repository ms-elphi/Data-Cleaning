{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear models are of the type y = w x + b, where the regression coefficient w represents the expected change in y for a one unit change in x (the predictor). Thus, the magnitude of w is partly determined by the magnitude of the units being used for x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Multiple predictors x1, x2, ...xn, predictors with greater numeric ranges dominate over those with smaller numeric ranges\n",
    "- Gradient descent converges faster when all the predictors (x1 to xn) are within a similar scale\n",
    "- SVM, feature scaling can decrease the time to find the support vectors\n",
    "- Feature scaling is required for methods that utilise distance calculations like k-nearest neighbours (KNN) and \n",
    "  k-means clustering( Euclidean Distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The machine learning models affected by the magnitude of the feature are:\n",
    "\n",
    "    Linear and Logistic Regression\n",
    "    Neural Networks\n",
    "    Support Vector Machines\n",
    "    KNN\n",
    "    K-means clustering\n",
    "    Linear Discriminant Analysis (LDA)\n",
    "    Principal Component Analysis (PCA)\n",
    "\n",
    "Machine learning models insensitive to feature magnitude are the ones based on Trees:\n",
    "\n",
    "    Classification and Regression Trees\n",
    "    Random Forests\n",
    "    Gradient Boosted Trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age     Fare\n",
       "0         0       3  22.0   7.2500\n",
       "1         1       1  38.0  71.2833\n",
       "2         1       3  26.0   7.9250\n",
       "3         1       1  35.0  53.1000\n",
       "4         0       3  35.0   8.0500"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\admin\\PP_programs\\DataRepo\\\\titanic\\\\train.csv', usecols = ['Pclass', 'Age', 'Fare', 'Survived'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Age        Fare\n",
       "count  891.000000  891.000000  714.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118   32.204208\n",
       "std      0.486592    0.836071   14.526497   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    7.910400\n",
       "50%      0.000000    3.000000   28.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000  512.329200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass _range:  2\n",
      "Age _range:  79.58\n",
      "Fare _range:  512.3292\n"
     ]
    }
   ],
   "source": [
    "#Range calculation = Max - Min\n",
    "for col in ['Pclass', 'Age', 'Fare']:\n",
    "    print(col, '_range: ', data[col].max()-data[col].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((623, 3), (268, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[['Pclass', 'Age', 'Fare']].fillna(0),\n",
    "                                                    data.Survived,test_size=0.3,random_state=12)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Scaling : \n",
    "X_std = (X - X.min() / (X.max - X.min())\n",
    "\n",
    "And converting scaled feature back to its initial format:\n",
    "X_scaled = X_std * (max - min) + min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  [0.6565008  0.28573616 0.06287472]\n",
      "Standard Deviation:  [0.4114945  0.21630472 0.09531884]\n",
      "Minimum value:  [0. 0. 0.]\n",
      "Maximum value:  [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print('Mean: ', X_train_scaled.mean(axis=0))\n",
    "print('Standard Deviation: ', X_train_scaled.std(axis=0))\n",
    "print('Minimum value: ', X_train_scaled.min(axis=0))\n",
    "print('Maximum value: ', X_train_scaled.max(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Logistic Regression roc-auc: 0.7175422241719676\n",
      "Test: Logistic Regression roc-auc: 0.70552040401695\n",
      "With Scaling\n",
      "Train: Logistic Regression roc-auc: 0.7175422241719677\n",
      "Test: Logistic Regression roc-auc: 0.70552040401695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Without Scaling\n",
    "print('Without Scaling')\n",
    "logit = LogisticRegression(random_state=12, C=1000) # c big to avoid regularization\n",
    "logit.fit(X_train, y_train)\n",
    "\n",
    "pred = logit.predict_proba(X_train)\n",
    "print('Train: Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "\n",
    "pred = logit.predict_proba(X_test)\n",
    "print('Test: Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "\n",
    "\n",
    "#With Scaling\n",
    "print('With Scaling')\n",
    "logit = LogisticRegression(random_state=12, C=1000) # c big to avoid regularization\n",
    "logit.fit(X_train_scaled, y_train)\n",
    "\n",
    "pred = logit.predict_proba(X_train_scaled)\n",
    "print('Train: Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "\n",
    "pred = logit.predict_proba(X_test_scaled)\n",
    "print('Test: Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation : \n",
    "    No Impact of scaling can be seen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Scaling\n",
      "Train: SVM roc-auc: 0.8866363237552094\n",
      "Test: SVM roc-auc: 0.636849132176235\n",
      "With Scaling\n",
      "Train: SVM roc-auc: 0.7150636104408862\n",
      "Test: SVM roc-auc: 0.6875834445927904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Without Scaling\n",
    "SVM_model = SVC(random_state=12, probability=True)\n",
    "SVM_model.fit(X_train, y_train)\n",
    "print('Without Scaling')\n",
    "pred = SVM_model.predict_proba(X_train)\n",
    "print('Train: SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "pred = SVM_model.predict_proba(X_test)\n",
    "print('Test: SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "\n",
    "#With Scaling\n",
    "SVM_model = SVC(random_state=12, probability=True)\n",
    "SVM_model.fit(X_train_scaled, y_train)\n",
    "print('With Scaling')\n",
    "pred = SVM_model.predict_proba(X_train_scaled)\n",
    "print('Train: SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "pred = SVM_model.predict_proba(X_test_scaled)\n",
    "print('Test: SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation : Impact of scaling on Test accuracy can be seen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Scaling\n",
      "Train: Neural Network roc-auc: 0.5553794691818381\n",
      "Test: Neural Network roc-auc: 0.6535670749405003\n",
      "With Scaling\n",
      "Train: Neural Network roc-auc: 0.7216001316078088\n",
      "Test: Neural Network roc-auc: 0.707784292099611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Without Scaling\n",
    "NN_model = MLPClassifier(random_state=12, solver='sgd')\n",
    "NN_model.fit(X_train, y_train)\n",
    "print('Without Scaling')\n",
    "pred = NN_model.predict_proba(X_train)\n",
    "print('Train: Neural Network roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "pred = NN_model.predict_proba(X_test)\n",
    "print('Test: Neural Network roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "\n",
    "#With Scaling\n",
    "print('With Scaling')\n",
    "NN_model = MLPClassifier(random_state=12, solver='sgd')\n",
    "NN_model.fit(X_train_scaled, y_train)\n",
    "pred = NN_model.predict_proba(X_train_scaled)\n",
    "print('Train: Neural Network roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "pred = NN_model.predict_proba(X_test_scaled)\n",
    "print('Test: Neural Network roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: Scaling the features improved the performance of the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Scaling\n",
      "KNN roc-auc: 0.8724720333406448\n",
      "KNN roc-auc: 0.6432054333313983\n",
      "With Scaling\n",
      "KNN roc-auc: 0.8812294362798858\n",
      "KNN roc-auc: 0.7090903813780693\n"
     ]
    }
   ],
   "source": [
    "#Without Scaling\n",
    "print('Without Scaling')\n",
    "KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "KNN.fit(X_train, y_train)\n",
    "pred = KNN.predict_proba(X_train)\n",
    "print('KNN roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "pred = KNN.predict_proba(X_test)\n",
    "print('KNN roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "\n",
    "#With Scaling\n",
    "print('With Scaling')\n",
    "KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "KNN.fit(X_train_scaled, y_train)\n",
    "pred = KNN.predict_proba(X_train_scaled)\n",
    "print('KNN roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "pred = KNN.predict_proba(X_test_scaled)\n",
    "print('KNN roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Scaling\n",
      "Train: Random Forests roc-auc: 0.9924270673393288\n",
      "Test: Random Forests roc-auc: 0.7350380217101062\n",
      "With Scaling\n",
      "Train: Random Forests roc-auc: 0.9923831980697522\n",
      "Test: Random Forests roc-auc: 0.7342833923492192\n"
     ]
    }
   ],
   "source": [
    "print('Without Scaling')\n",
    "rf = RandomForestClassifier(n_estimators=700, random_state=12)\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict_proba(X_train)\n",
    "print('Train: Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "pred = rf.predict_proba(X_test)\n",
    "print('Test: Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "\n",
    "print('With Scaling')\n",
    "rf = RandomForestClassifier(n_estimators=700, random_state=12)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "pred = rf.predict_proba(X_train_scaled)\n",
    "print('Train: Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "pred = rf.predict_proba(X_test_scaled)\n",
    "print('Test: Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: No change in performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Scaling\n",
      "Train: AdaBoost roc-auc: 0.8555878482123273\n",
      "Test: AdaBoost roc-auc: 0.7204098217913738\n",
      "With Scaling\n",
      "Train: AdaBoost roc-auc: 0.8555878482123273\n",
      "Test: AdaBoost roc-auc: 0.7023567655424624\n"
     ]
    }
   ],
   "source": [
    "print('Without Scaling')\n",
    "ada = AdaBoostClassifier(n_estimators=250, random_state=12)\n",
    "ada.fit(X_train, y_train)\n",
    "pred = ada.predict_proba(X_train)\n",
    "print('Train: AdaBoost roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "pred = ada.predict_proba(X_test)\n",
    "print('Test: AdaBoost roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "\n",
    "print('With Scaling')\n",
    "ada = AdaBoostClassifier(n_estimators=250, random_state=12)\n",
    "ada.fit(X_train_scaled, y_train)\n",
    "pred = ada.predict_proba(X_train_scaled)\n",
    "print('Train: AdaBoost roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "pred = ada.predict_proba(X_test_scaled)\n",
    "print('Test: AdaBoost roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: No change in performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
